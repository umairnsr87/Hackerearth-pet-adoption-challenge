{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nfrom sklearn.ensemble import StackingClassifier\n# from sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold,RepeatedStratifiedKFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import StackingRegressor\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom lightgbm import LGBMClassifier\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.linear_model import LogisticRegression\nimport scipy.stats as st\nimport sklearn.metrics as metrics\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV,cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import r2_score,roc_auc_score,recall_score,classification_report,mean_squared_error,accuracy_score,f1_score,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":14,"outputs":[{"output_type":"stream","text":"/kaggle/input/petadoption-mod/test_mod.csv\n/kaggle/input/petadoption-mod/train_mod.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/petadoption-mod/train_mod.csv\")\ntest=pd.read_csv(\"../input/petadoption-mod/test_mod.csv\")\n\n\n\n#label encoding the features for the modelling process\nle=LabelEncoder()\nle.fit(train[\"color_type\"])\n# train[\"color_type\"]=le.fit_transform(train[\"color_type\"])\ntrain[\"color_type\"]=le.transform(train[\"color_type\"])\ntest[\"color_type\"]=le.transform(test[\"color_type\"])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set,val_set=train_test_split(train,test_size=.25,random_state=42)\ntrain_set.shape,val_set.shape\n\n#-------------------------------------------------------------------------------\n#train_set\ntrain_data=train_set.drop(['pet_id', 'issue_date', 'listing_date','breed_category', 'pet_category','days_stayed']\n                          ,axis=1)\ntrain_res_breed=train_set.breed_category\ntrain_res_pet=train_set.pet_category\n\n#-------------------------------------------------------------------------------\n#val_set\nval_data=val_set.drop(['pet_id', 'issue_date', 'listing_date','breed_category', 'pet_category','days_stayed'],\n                     axis=1)\nval_res_breed=val_set.breed_category\nval_res_pet=val_set.pet_category\n#-------------------------------------------------------------------------------\ntrain_full=train.drop(['pet_id', 'issue_date', 'listing_date','breed_category', 'pet_category','days_stayed']\n                          ,axis=1)\ntrain_full_breed=train.breed_category\ntrain_full_pet=train.pet_category\ntest_full=test.drop(['pet_id', 'issue_date', 'listing_date','days_stayed']\n                          ,axis=1)\n\n#-------------------------------------------------------------------------------\n\ntrain_data.shape,train_res_breed.shape,val_data.shape,val_res_breed.shape,train_full.shape,test_full.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"((14125, 9), (14125,), (4709, 9), (4709,), (18834, 9), (8072, 9))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbc=LGBMClassifier()","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=[lgbc]\nsctr,scte,auc,ps,rs=[],[],[],[],[]\ndef ensemble_for_train_val(X_train,y_train,X_test, y_test):\n    for model in models:\n        print(model.__class__.__name__)\n        model.fit(X_train, y_train)\n        y_test_pred = model.predict(X_test)\n        y_test_pred_new=model.predict_proba(X_test)\n        y_test_pred_new=y_test_pred_new[:,1]\n        train_score=model.score(X_train,y_train)\n        test_score=model.score(X_test,y_test)\n        p_score=metrics.precision_score(y_test,y_test_pred,average='micro')\n        r_score=metrics.recall_score(y_test,y_test_pred,average='micro')\n        \n        sctr.append(train_score)\n        scte.append(test_score)\n        ps.append(p_score)\n        rs.append(r_score)\n    return sctr,scte,ps,rs\n\n\n","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nensemble_for_train_val(train_data,train_res_breed, val_data, val_res_breed)\n# 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n\nensemble=pd.DataFrame({'names':[\"lgbc\"],\n                       'training':sctr,'testing':scte,'precision':ps,'recall':rs,})\n\nensemble=ensemble.sort_values(by='precision',ascending=False).reset_index(drop=True)\nensemble","execution_count":19,"outputs":[{"output_type":"stream","text":"LGBMClassifier\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"  names  training   testing  precision    recall\n0  lgbc  0.976212  0.901253   0.901253  0.901253","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>names</th>\n      <th>training</th>\n      <th>testing</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lgbc</td>\n      <td>0.976212</td>\n      <td>0.901253</td>\n      <td>0.901253</td>\n      <td>0.901253</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"help(GridSearchCV)","execution_count":20,"outputs":[{"output_type":"stream","text":"Help on class GridSearchCV in module sklearn.model_selection._search:\n\nclass GridSearchCV(BaseSearchCV)\n |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n |  \n |  Exhaustive search over specified parameter values for an estimator.\n |  \n |  Important members are fit, predict.\n |  \n |  GridSearchCV implements a \"fit\" and a \"score\" method.\n |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n |  \"transform\" and \"inverse_transform\" if they are implemented in the\n |  estimator used.\n |  \n |  The parameters of the estimator used to apply these methods are optimized\n |  by cross-validated grid-search over a parameter grid.\n |  \n |  Read more in the :ref:`User Guide <grid_search>`.\n |  \n |  Parameters\n |  ----------\n |  estimator : estimator object.\n |      This is assumed to implement the scikit-learn estimator interface.\n |      Either estimator needs to provide a ``score`` function,\n |      or ``scoring`` must be passed.\n |  \n |  param_grid : dict or list of dictionaries\n |      Dictionary with parameters names (`str`) as keys and lists of\n |      parameter settings to try as values, or a list of such\n |      dictionaries, in which case the grids spanned by each dictionary\n |      in the list are explored. This enables searching over any sequence\n |      of parameter settings.\n |  \n |  scoring : str, callable, list/tuple or dict, default=None\n |      A single str (see :ref:`scoring_parameter`) or a callable\n |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n |  \n |      For evaluating multiple metrics, either give a list of (unique) strings\n |      or a dict with names as keys and callables as values.\n |  \n |      NOTE that when using custom scorers, each scorer should return a single\n |      value. Metric functions returning a list/array of values can be wrapped\n |      into multiple scorers that return one value each.\n |  \n |      See :ref:`multimetric_grid_search` for an example.\n |  \n |      If None, the estimator's score method is used.\n |  \n |  n_jobs : int, default=None\n |      Number of jobs to run in parallel.\n |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n |      for more details.\n |  \n |      .. versionchanged:: v0.20\n |         `n_jobs` default changed from 1 to None\n |  \n |  pre_dispatch : int, or str, default=n_jobs\n |      Controls the number of jobs that get dispatched during parallel\n |      execution. Reducing this number can be useful to avoid an\n |      explosion of memory consumption when more jobs get dispatched\n |      than CPUs can process. This parameter can be:\n |  \n |          - None, in which case all the jobs are immediately\n |            created and spawned. Use this for lightweight and\n |            fast-running jobs, to avoid delays due to on-demand\n |            spawning of the jobs\n |  \n |          - An int, giving the exact number of total jobs that are\n |            spawned\n |  \n |          - A str, giving an expression as a function of n_jobs,\n |            as in '2*n_jobs'\n |  \n |  iid : bool, default=False\n |      If True, return the average score across folds, weighted by the number\n |      of samples in each test set. In this case, the data is assumed to be\n |      identically distributed across the folds, and the loss minimized is\n |      the total loss per sample, and not the mean loss across the folds.\n |  \n |      .. deprecated:: 0.22\n |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n |  \n |  cv : int, cross-validation generator or an iterable, default=None\n |      Determines the cross-validation splitting strategy.\n |      Possible inputs for cv are:\n |  \n |      - None, to use the default 5-fold cross validation,\n |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n |      - :term:`CV splitter`,\n |      - An iterable yielding (train, test) splits as arrays of indices.\n |  \n |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n |      other cases, :class:`KFold` is used.\n |  \n |      Refer :ref:`User Guide <cross_validation>` for the various\n |      cross-validation strategies that can be used here.\n |  \n |      .. versionchanged:: 0.22\n |          ``cv`` default value if None changed from 3-fold to 5-fold.\n |  \n |  refit : bool, str, or callable, default=True\n |      Refit an estimator using the best found parameters on the whole\n |      dataset.\n |  \n |      For multiple metric evaluation, this needs to be a `str` denoting the\n |      scorer that would be used to find the best parameters for refitting\n |      the estimator at the end.\n |  \n |      Where there are considerations other than maximum score in\n |      choosing a best estimator, ``refit`` can be set to a function which\n |      returns the selected ``best_index_`` given ``cv_results_``. In that\n |      case, the ``best_estimator_`` and ``best_params_`` will be set\n |      according to the returned ``best_index_`` while the ``best_score_``\n |      attribute will not be available.\n |  \n |      The refitted estimator is made available at the ``best_estimator_``\n |      attribute and permits using ``predict`` directly on this\n |      ``GridSearchCV`` instance.\n |  \n |      Also for multiple metric evaluation, the attributes ``best_index_``,\n |      ``best_score_`` and ``best_params_`` will only be available if\n |      ``refit`` is set and all of them will be determined w.r.t this specific\n |      scorer.\n |  \n |      See ``scoring`` parameter to know more about multiple metric\n |      evaluation.\n |  \n |      .. versionchanged:: 0.20\n |          Support for callable added.\n |  \n |  verbose : integer\n |      Controls the verbosity: the higher, the more messages.\n |  \n |  error_score : 'raise' or numeric, default=np.nan\n |      Value to assign to the score if an error occurs in estimator fitting.\n |      If set to 'raise', the error is raised. If a numeric value is given,\n |      FitFailedWarning is raised. This parameter does not affect the refit\n |      step, which will always raise the error.\n |  \n |  return_train_score : bool, default=False\n |      If ``False``, the ``cv_results_`` attribute will not include training\n |      scores.\n |      Computing training scores is used to get insights on how different\n |      parameter settings impact the overfitting/underfitting trade-off.\n |      However computing the scores on the training set can be computationally\n |      expensive and is not strictly required to select the parameters that\n |      yield the best generalization performance.\n |  \n |      .. versionadded:: 0.19\n |  \n |      .. versionchanged:: 0.21\n |          Default value was changed from ``True`` to ``False``\n |  \n |  \n |  Examples\n |  --------\n |  >>> from sklearn import svm, datasets\n |  >>> from sklearn.model_selection import GridSearchCV\n |  >>> iris = datasets.load_iris()\n |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n |  >>> svc = svm.SVC()\n |  >>> clf = GridSearchCV(svc, parameters)\n |  >>> clf.fit(iris.data, iris.target)\n |  GridSearchCV(estimator=SVC(),\n |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n |  >>> sorted(clf.cv_results_.keys())\n |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n |   'param_C', 'param_kernel', 'params',...\n |   'rank_test_score', 'split0_test_score',...\n |   'split2_test_score', ...\n |   'std_fit_time', 'std_score_time', 'std_test_score']\n |  \n |  Attributes\n |  ----------\n |  cv_results_ : dict of numpy (masked) ndarrays\n |      A dict with keys as column headers and values as columns, that can be\n |      imported into a pandas ``DataFrame``.\n |  \n |      For instance the below given table\n |  \n |      +------------+-----------+------------+-----------------+---+---------+\n |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n |      +============+===========+============+=================+===+=========+\n |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n |      +------------+-----------+------------+-----------------+---+---------+\n |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n |      +------------+-----------+------------+-----------------+---+---------+\n |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n |      +------------+-----------+------------+-----------------+---+---------+\n |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n |      +------------+-----------+------------+-----------------+---+---------+\n |  \n |      will be represented by a ``cv_results_`` dict of::\n |  \n |          {\n |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n |                                       mask = [False False False False]...)\n |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n |                                      mask = [ True  True False False]...),\n |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n |                                       mask = [False False  True  True]...),\n |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n |          'rank_test_score'    : [2, 4, 3, 1],\n |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n |          }\n |  \n |      NOTE\n |  \n |      The key ``'params'`` is used to store a list of parameter\n |      settings dicts for all the parameter candidates.\n |  \n |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n |      ``std_score_time`` are all in seconds.\n |  \n |      For multi-metric evaluation, the scores for all the scorers are\n |      available in the ``cv_results_`` dict at the keys ending with that\n |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n |  \n |  best_estimator_ : estimator\n |      Estimator that was chosen by the search, i.e. estimator\n |      which gave highest score (or smallest loss if specified)\n |      on the left out data. Not available if ``refit=False``.\n |  \n |      See ``refit`` parameter for more information on allowed values.\n |  \n |  best_score_ : float\n |      Mean cross-validated score of the best_estimator\n |  \n |      For multi-metric evaluation, this is present only if ``refit`` is\n |      specified.\n |  \n |      This attribute is not available if ``refit`` is a function.\n |  \n |  best_params_ : dict\n |      Parameter setting that gave the best results on the hold out data.\n |  \n |      For multi-metric evaluation, this is present only if ``refit`` is\n |      specified.\n |  \n |  best_index_ : int\n |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n |      candidate parameter setting.\n |  \n |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n |      the parameter setting for the best model, that gives the highest\n |      mean score (``search.best_score_``).\n |  \n |      For multi-metric evaluation, this is present only if ``refit`` is\n |      specified.\n |  \n |  scorer_ : function or a dict\n |      Scorer function used on the held out data to choose the best\n |      parameters for the model.\n |  \n |      For multi-metric evaluation, this attribute holds the validated\n |      ``scoring`` dict which maps the scorer key to the scorer callable.\n |  \n |  n_splits_ : int\n |      The number of cross-validation splits (folds/iterations).\n |  \n |  refit_time_ : float\n |      Seconds used for refitting the best model on the whole dataset.\n |  \n |      This is present only if ``refit`` is not False.\n |  \n |      .. versionadded:: 0.20\n |  \n |  Notes\n |  -----\n |  The parameters selected are those that maximize the score of the left out\n |  data, unless an explicit score is passed in which case it is used instead.\n |  \n |  If `n_jobs` was set to a value higher than one, the data is copied for each\n |  point in the grid (and not `n_jobs` times). This is done for efficiency\n |  reasons if individual jobs take very little time, but may raise errors if\n |  the dataset is large and not enough memory is available.  A workaround in\n |  this case is to set `pre_dispatch`. Then, the memory is copied only\n |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n |  n_jobs`.\n |  \n |  See Also\n |  ---------\n |  :class:`ParameterGrid`:\n |      generates all the combinations of a hyperparameter grid.\n |  \n |  :func:`sklearn.model_selection.train_test_split`:\n |      utility function to split the data into a development set usable\n |      for fitting a GridSearchCV instance and an evaluation set for\n |      its final evaluation.\n |  \n |  :func:`sklearn.metrics.make_scorer`:\n |      Make a scorer from a performance metric or loss function.\n |  \n |  Method resolution order:\n |      GridSearchCV\n |      BaseSearchCV\n |      sklearn.base.MetaEstimatorMixin\n |      sklearn.base.BaseEstimator\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from BaseSearchCV:\n |  \n |  decision_function(self, X)\n |      Call decision_function on the estimator with the best found parameters.\n |      \n |      Only available if ``refit=True`` and the underlying estimator supports\n |      ``decision_function``.\n |      \n |      Parameters\n |      ----------\n |      X : indexable, length n_samples\n |          Must fulfill the input assumptions of the\n |          underlying estimator.\n |  \n |  fit(self, X, y=None, *, groups=None, **fit_params)\n |      Run fit with all sets of parameters.\n |      \n |      Parameters\n |      ----------\n |      \n |      X : array-like of shape (n_samples, n_features)\n |          Training vector, where n_samples is the number of samples and\n |          n_features is the number of features.\n |      \n |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n |          Target relative to X for classification or regression;\n |          None for unsupervised learning.\n |      \n |      groups : array-like of shape (n_samples,), default=None\n |          Group labels for the samples used while splitting the dataset into\n |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n |      \n |      **fit_params : dict of str -> object\n |          Parameters passed to the ``fit`` method of the estimator\n |  \n |  inverse_transform(self, Xt)\n |      Call inverse_transform on the estimator with the best found params.\n |      \n |      Only available if the underlying estimator implements\n |      ``inverse_transform`` and ``refit=True``.\n |      \n |      Parameters\n |      ----------\n |      Xt : indexable, length n_samples\n |          Must fulfill the input assumptions of the\n |          underlying estimator.\n |  \n |  predict(self, X)\n |      Call predict on the estimator with the best found parameters.\n |      \n |      Only available if ``refit=True`` and the underlying estimator supports\n |      ``predict``.\n |      \n |      Parameters\n |      ----------\n |      X : indexable, length n_samples\n |          Must fulfill the input assumptions of the\n |          underlying estimator.\n |  \n |  predict_log_proba(self, X)\n |      Call predict_log_proba on the estimator with the best found parameters.\n |      \n |      Only available if ``refit=True`` and the underlying estimator supports\n |      ``predict_log_proba``.\n |      \n |      Parameters\n |      ----------\n |      X : indexable, length n_samples\n |          Must fulfill the input assumptions of the\n |          underlying estimator.\n |  \n |  predict_proba(self, X)\n |      Call predict_proba on the estimator with the best found parameters.\n |      \n |      Only available if ``refit=True`` and the underlying estimator supports\n |      ``predict_proba``.\n |      \n |      Parameters\n |      ----------\n |      X : indexable, length n_samples\n |          Must fulfill the input assumptions of the\n |          underlying estimator.\n |  \n |  score(self, X, y=None)\n |      Returns the score on the given data, if the estimator has been refit.\n |      \n |      This uses the score defined by ``scoring`` where provided, and the\n |      ``best_estimator_.score`` method otherwise.\n |      \n |      Parameters\n |      ----------\n |      X : array-like of shape (n_samples, n_features)\n |          Input data, where n_samples is the number of samples and\n |          n_features is the number of features.\n |      \n |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n |          Target relative to X for classification or regression;\n |          None for unsupervised learning.\n |      \n |      Returns\n |      -------\n |      score : float\n |  \n |  transform(self, X)\n |      Call transform on the estimator with the best found parameters.\n |      \n |      Only available if the underlying estimator supports ``transform`` and\n |      ``refit=True``.\n |      \n |      Parameters\n |      ----------\n |      X : indexable, length n_samples\n |          Must fulfill the input assumptions of the\n |          underlying estimator.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from BaseSearchCV:\n |  \n |  classes_\n |  \n |  n_features_in_\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, default=True\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : mapping of string to any\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      The method works on simple estimators as well as on nested objects\n |      (such as pipelines). The latter have parameters of the form\n |      ``<component>__<parameter>`` so that it's possible to update each\n |      component of a nested object.\n |      \n |      Parameters\n |      ----------\n |      **params : dict\n |          Estimator parameters.\n |      \n |      Returns\n |      -------\n |      self : object\n |          Estimator instance.\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"help(lgbc)\n","execution_count":21,"outputs":[{"output_type":"stream","text":"Help on LGBMClassifier in module lightgbm.sklearn object:\n\nclass LGBMClassifier(LGBMModel, sklearn.base.ClassifierMixin)\n |  LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, importance_type='split', **kwargs)\n |  \n |  LightGBM classifier.\n |  \n |  Method resolution order:\n |      LGBMClassifier\n |      LGBMModel\n |      sklearn.base.BaseEstimator\n |      sklearn.base.ClassifierMixin\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  fit(self, X, y, sample_weight=None, init_score=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_class_weight=None, eval_init_score=None, eval_metric=None, early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None)\n |      Build a gradient boosting model from the training set (X, y).\n |      \n |      Parameters\n |      ----------\n |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n |          Input feature matrix.\n |      y : array-like of shape = [n_samples]\n |          The target values (class labels in classification, real numbers in regression).\n |      sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n |          Weights of training data.\n |      init_score : array-like of shape = [n_samples] or None, optional (default=None)\n |          Init score of training data.\n |      group : array-like or None, optional (default=None)\n |          Group data of training data.\n |      eval_set : list or None, optional (default=None)\n |          A list of (X, y) tuple pairs to use as validation sets.\n |      eval_names : list of strings or None, optional (default=None)\n |          Names of eval_set.\n |      eval_sample_weight : list of arrays or None, optional (default=None)\n |          Weights of eval data.\n |      eval_class_weight : list or None, optional (default=None)\n |          Class weights of eval data.\n |      eval_init_score : list of arrays or None, optional (default=None)\n |          Init score of eval data.\n |      eval_group : list of arrays or None, optional (default=None)\n |          Group data of eval data.\n |      eval_metric : string, list of strings, callable or None, optional (default=None)\n |          If string, it should be a built-in evaluation metric to use.\n |          If callable, it should be a custom evaluation metric, see note below for more details.\n |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n |      early_stopping_rounds : int or None, optional (default=None)\n |          Activates early stopping. The model will train until the validation score stops improving.\n |          Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n |          to continue training.\n |          Requires at least one validation data and one metric.\n |          If there's more than one, will check all of them. But the training data is ignored anyway.\n |          To check only the first metric, set the ``first_metric_only`` parameter to ``True``\n |          in additional parameters ``**kwargs`` of the model constructor.\n |      verbose : bool or int, optional (default=True)\n |          Requires at least one evaluation data.\n |          If True, the eval metric on the eval set is printed at each boosting stage.\n |          If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.\n |          The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n |      \n |          .. rubric:: Example\n |      \n |          With ``verbose`` = 4 and at least one item in ``eval_set``,\n |          an evaluation metric is printed every 4 (instead of 1) boosting stages.\n |      \n |      feature_name : list of strings or 'auto', optional (default='auto')\n |          Feature names.\n |          If 'auto' and data is pandas DataFrame, data columns names are used.\n |      categorical_feature : list of strings or int, or 'auto', optional (default='auto')\n |          Categorical features.\n |          If list of int, interpreted as indices.\n |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n |          All values in categorical features should be less than int32 max value (2147483647).\n |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n |          All negative values in categorical features will be treated as missing values.\n |          The output cannot be monotonically constrained with respect to a categorical feature.\n |      callbacks : list of callback functions or None, optional (default=None)\n |          List of callback functions that are applied at each iteration.\n |          See Callbacks in Python API for more information.\n |      \n |      Returns\n |      -------\n |      self : object\n |          Returns self.\n |      \n |      Note\n |      ----\n |      Custom eval function expects a callable with following signatures:\n |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n |      ``func(y_true, y_pred, weight, group)``\n |      and returns (eval_name, eval_result, is_higher_better) or\n |      list of (eval_name, eval_result, is_higher_better):\n |      \n |          y_true : array-like of shape = [n_samples]\n |              The target values.\n |          y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n |              The predicted values.\n |          weight : array-like of shape = [n_samples]\n |              The weight of samples.\n |          group : array-like\n |              Group/query data, used for ranking task.\n |          eval_name : string\n |              The name of evaluation function (without whitespaces).\n |          eval_result : float\n |              The eval result.\n |          is_higher_better : bool\n |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n |      \n |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n |  \n |  predict(self, X, raw_score=False, num_iteration=None, pred_leaf=False, pred_contrib=False, **kwargs)\n |      Return the predicted value for each sample.\n |      \n |      Parameters\n |      ----------\n |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n |          Input features matrix.\n |      raw_score : bool, optional (default=False)\n |          Whether to predict raw scores.\n |      num_iteration : int or None, optional (default=None)\n |          Limit number of iterations in the prediction.\n |          If None, if the best iteration exists, it is used; otherwise, all trees are used.\n |          If <= 0, all trees are used (no limits).\n |      pred_leaf : bool, optional (default=False)\n |          Whether to predict leaf index.\n |      pred_contrib : bool, optional (default=False)\n |          Whether to predict feature contributions.\n |      \n |          .. note::\n |      \n |              If you want to get more explanations for your model's predictions using SHAP values,\n |              like SHAP interaction values,\n |              you can install the shap package (https://github.com/slundberg/shap).\n |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n |              column, where the last column is the expected value.\n |      \n |      **kwargs\n |          Other parameters for the prediction.\n |      \n |      Returns\n |      -------\n |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n |          The predicted values.\n |      X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes]\n |          If ``pred_contrib=True``, the feature contributions for each sample.\n |  \n |  predict_proba(self, X, raw_score=False, num_iteration=None, pred_leaf=False, pred_contrib=False, **kwargs)\n |      Return the predicted probability for each class for each sample.\n |      \n |      Parameters\n |      ----------\n |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n |          Input features matrix.\n |      raw_score : bool, optional (default=False)\n |          Whether to predict raw scores.\n |      num_iteration : int or None, optional (default=None)\n |          Limit number of iterations in the prediction.\n |          If None, if the best iteration exists, it is used; otherwise, all trees are used.\n |          If <= 0, all trees are used (no limits).\n |      pred_leaf : bool, optional (default=False)\n |          Whether to predict leaf index.\n |      pred_contrib : bool, optional (default=False)\n |          Whether to predict feature contributions.\n |      \n |          .. note::\n |      \n |              If you want to get more explanations for your model's predictions using SHAP values,\n |              like SHAP interaction values,\n |              you can install the shap package (https://github.com/slundberg/shap).\n |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n |              column, where the last column is the expected value.\n |      \n |      **kwargs\n |          Other parameters for the prediction.\n |      \n |      Returns\n |      -------\n |      predicted_probability : array-like of shape = [n_samples, n_classes]\n |          The predicted probability for each class for each sample.\n |      X_leaves : array-like of shape = [n_samples, n_trees * n_classes]\n |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n |      X_SHAP_values : array-like of shape = [n_samples, (n_features + 1) * n_classes]\n |          If ``pred_contrib=True``, the feature contributions for each sample.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  classes_\n |      Get the class label array.\n |  \n |  n_classes_\n |      Get the number of classes.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from LGBMModel:\n |  \n |  __init__(self, boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, importance_type='split', **kwargs)\n |      Construct a gradient boosting model.\n |      \n |      Parameters\n |      ----------\n |      boosting_type : string, optional (default='gbdt')\n |          'gbdt', traditional Gradient Boosting Decision Tree.\n |          'dart', Dropouts meet Multiple Additive Regression Trees.\n |          'goss', Gradient-based One-Side Sampling.\n |          'rf', Random Forest.\n |      num_leaves : int, optional (default=31)\n |          Maximum tree leaves for base learners.\n |      max_depth : int, optional (default=-1)\n |          Maximum tree depth for base learners, <=0 means no limit.\n |      learning_rate : float, optional (default=0.1)\n |          Boosting learning rate.\n |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n |          in training using ``reset_parameter`` callback.\n |          Note, that this will ignore the ``learning_rate`` argument in training.\n |      n_estimators : int, optional (default=100)\n |          Number of boosted trees to fit.\n |      subsample_for_bin : int, optional (default=200000)\n |          Number of samples for constructing bins.\n |      objective : string, callable or None, optional (default=None)\n |          Specify the learning task and the corresponding learning objective or\n |          a custom objective function to be used (see note below).\n |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n |      class_weight : dict, 'balanced' or None, optional (default=None)\n |          Weights associated with classes in the form ``{class_label: weight}``.\n |          Use this parameter only for multi-class classification task;\n |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n |          You may want to consider performing probability calibration\n |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n |          The 'balanced' mode uses the values of y to automatically adjust weights\n |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n |          If None, all classes are supposed to have weight one.\n |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n |          if ``sample_weight`` is specified.\n |      min_split_gain : float, optional (default=0.)\n |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n |      min_child_weight : float, optional (default=1e-3)\n |          Minimum sum of instance weight (hessian) needed in a child (leaf).\n |      min_child_samples : int, optional (default=20)\n |          Minimum number of data needed in a child (leaf).\n |      subsample : float, optional (default=1.)\n |          Subsample ratio of the training instance.\n |      subsample_freq : int, optional (default=0)\n |          Frequence of subsample, <=0 means no enable.\n |      colsample_bytree : float, optional (default=1.)\n |          Subsample ratio of columns when constructing each tree.\n |      reg_alpha : float, optional (default=0.)\n |          L1 regularization term on weights.\n |      reg_lambda : float, optional (default=0.)\n |          L2 regularization term on weights.\n |      random_state : int or None, optional (default=None)\n |          Random number seed.\n |          If None, default seeds in C++ code will be used.\n |      n_jobs : int, optional (default=-1)\n |          Number of parallel threads.\n |      silent : bool, optional (default=True)\n |          Whether to print messages while running boosting.\n |      importance_type : string, optional (default='split')\n |          The type of feature importance to be filled into ``feature_importances_``.\n |          If 'split', result contains numbers of times the feature is used in a model.\n |          If 'gain', result contains total gains of splits which use the feature.\n |      **kwargs\n |          Other parameters for the model.\n |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n |      \n |          .. warning::\n |      \n |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n |      \n |      Attributes\n |      ----------\n |      n_features_ : int\n |          The number of features of fitted model.\n |      classes_ : array of shape = [n_classes]\n |          The class label array (only for classification problem).\n |      n_classes_ : int\n |          The number of classes (only for classification problem).\n |      best_score_ : dict or None\n |          The best score of fitted model.\n |      best_iteration_ : int or None\n |          The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n |      objective_ : string or callable\n |          The concrete objective used while fitting this model.\n |      booster_ : Booster\n |          The underlying Booster of this model.\n |      evals_result_ : dict or None\n |          The evaluation results if ``early_stopping_rounds`` has been specified.\n |      feature_importances_ : array of shape = [n_features]\n |          The feature importances (the higher, the more important the feature).\n |      \n |      Note\n |      ----\n |      A custom objective function can be provided for the ``objective`` parameter.\n |      In this case, it should have the signature\n |      ``objective(y_true, y_pred) -> grad, hess`` or\n |      ``objective(y_true, y_pred, group) -> grad, hess``:\n |      \n |          y_true : array-like of shape = [n_samples]\n |              The target values.\n |          y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n |              The predicted values.\n |          group : array-like\n |              Group/query data, used for ranking task.\n |          grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n |              The value of the first order derivative (gradient) for each sample point.\n |          hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n |              The value of the second order derivative (Hessian) for each sample point.\n |      \n |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n |      and you should group grad and hess in this way as well.\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, optional (default=True)\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : dict\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      Parameters\n |      ----------\n |      **params\n |          Parameter names with their new values.\n |      \n |      Returns\n |      -------\n |      self : object\n |          Returns self.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from LGBMModel:\n |  \n |  best_iteration_\n |      Get the best iteration of fitted model.\n |  \n |  best_score_\n |      Get the best score of fitted model.\n |  \n |  booster_\n |      Get the underlying lightgbm Booster of this model.\n |  \n |  evals_result_\n |      Get the evaluation results.\n |  \n |  feature_importances_\n |      Get feature importances.\n |      \n |      .. note::\n |      \n |          Feature importance in sklearn interface used to normalize to 1,\n |          it's deprecated after 2.0.4 and is the same as Booster.feature_importance() now.\n |          ``importance_type`` attribute is passed to the function\n |          to configure the type of importance values to be extracted.\n |  \n |  n_features_\n |      Get the number of features of fitted model.\n |  \n |  objective_\n |      Get the concrete objective used while fitting this model.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.BaseEstimator:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.ClassifierMixin:\n |  \n |  score(self, X, y, sample_weight=None)\n |      Return the mean accuracy on the given test data and labels.\n |      \n |      In multi-label classification, this is the subset accuracy\n |      which is a harsh metric since you require for each sample that\n |      each label set be correctly predicted.\n |      \n |      Parameters\n |      ----------\n |      X : array-like of shape (n_samples, n_features)\n |          Test samples.\n |      \n |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n |          True labels for X.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          Sample weights.\n |      \n |      Returns\n |      -------\n |      score : float\n |          Mean accuracy of self.predict(X) wrt. y.\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prec(x,y):\n    prec=metrics.precision_score(x,y,average='micro')\n    return prec","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# ensemble_for_train_val(train_data,train_res_pet, val_data, val_res_pet)\n# # 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n\n# ensemble=pd.DataFrame({'names':[\"lgbc\"],\n#                        'training':sctr,'testing':scte,'precision':ps,'recall':rs,})\n\n# ensemble=ensemble.sort_values(by='precision',ascending=False).reset_index(drop=True)\n# ensemble\n\nparam_dict={\n    'boosting_type' :[\"dart\"],\n    'is_unbalance':[True],\n    'n_estimators':[20,30,50],\n    'num_leaves':[8,10,12], \n    'max_depth':[None,8,10,12],\n#     'feature_fraction':[0.5,.75],  \n#     'bagging_fraction':[0.8,.5], \n#     'bagging_freq':[15,20], \n    'learning_rate':[.1]\n}\n\ngridSearchCV = GridSearchCV(estimator = lgbc, \n    param_grid = param_dict, \n    scoring='accuracy',\n    n_jobs=-1,\n    iid=False, \n    verbose=1,\n    cv=3)\ngridSearchCV.fit(train_full,train_full_breed)\n","execution_count":23,"outputs":[{"output_type":"stream","text":"Fitting 3 folds for each of 36 candidates, totalling 108 fits\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.5s\n[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   14.0s finished\n","name":"stderr"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"GridSearchCV(cv=3, estimator=LGBMClassifier(), iid=False, n_jobs=-1,\n             param_grid={'boosting_type': ['dart'], 'is_unbalance': [True],\n                         'learning_rate': [0.1], 'max_depth': [None, 8, 10, 12],\n                         'n_estimators': [20, 30, 50],\n                         'num_leaves': [8, 10, 12]},\n             scoring='accuracy', verbose=1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":" gridSearchCV.best_params_, gridSearchCV.best_score_","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"({'boosting_type': 'dart',\n  'is_unbalance': True,\n  'learning_rate': 0.1,\n  'max_depth': None,\n  'n_estimators': 30,\n  'num_leaves': 8},\n 0.9052245938196878)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# ensemble_for_train_val(train_data,train_res_pet, val_data, val_res_pet)\n# # 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n\n# ensemble=pd.DataFrame({'names':[\"lgbc\"],\n#                        'training':sctr,'testing':scte,'precision':ps,'recall':rs,})\n\n# ensemble=ensemble.sort_values(by='precision',ascending=False).reset_index(drop=True)\n# ensemble\n\nparam_dict={\n    'boosting_type' :[\"dart\"],\n    'is_unbalance':[True],\n    'n_estimators':[400,500,600],\n    'num_leaves':[10,20], \n    'max_depth':[8,10,12],\n#     'feature_fraction':[0.5,.75],  \n#     'bagging_fraction':[0.8,.5], \n#     'bagging_freq':[15,20], \n    'learning_rate':[0.01,.1]\n}\n\ngridSearchCV = GridSearchCV(estimator = lgbc, \n    param_grid = param_dict, \n    scoring='accuracy',\n    n_jobs=-1,\n    iid=False, \n    verbose=1,\n    cv=3)\ngridSearchCV.fit(train_full,train_full_pet)\ngridSearchCV.best_params_, gridSearchCV.best_score_","execution_count":26,"outputs":[{"output_type":"stream","text":"Fitting 3 folds for each of 36 candidates, totalling 108 fits\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.1min\n[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 22.9min finished\n","name":"stderr"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"({'boosting_type': 'dart',\n  'is_unbalance': True,\n  'learning_rate': 0.1,\n  'max_depth': 12,\n  'n_estimators': 600,\n  'num_leaves': 20},\n 0.9047998300945098)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbc=LGBMClassifier(boosting_type= 'dart',is_unbalance= True,learning_rate= 0.1,max_depth= None,n_estimators= 30,num_leaves= 8)\nlgbc.fit(train_full,train_full_breed)\ny_test_pred_breed = lgbc.predict(test_full)\n\nlgbc=LGBMClassifier(boosting_type= 'dart',is_unbalance=True,learning_rate= 0.1,max_depth= 12,n_estimators= 600,num_leaves= 20)\nlgbc.fit(train_full,train_full_breed)\ny_test_pred2_pet=lgbc.predict(test_full)\nid=pd.Series(test[\"pet_id\"])\nsubmission=pd.DataFrame({'pet_id':id,'breed_category':y_test_pred_breed,'pet_category':y_test_pred2_pet})\nsubmission.to_csv(\"pet_doption_hyperparametertuned.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}