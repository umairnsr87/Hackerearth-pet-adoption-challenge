{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport seaborn as sns\nfrom sklearn.ensemble import StackingClassifier\n# from sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold,RepeatedStratifiedKFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import StackingRegressor\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom lightgbm import LGBMClassifier\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.linear_model import LogisticRegression\nimport scipy.stats as st\nimport sklearn.metrics as metrics\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV,cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import r2_score,roc_auc_score,recall_score,classification_report,mean_squared_error,accuracy_score,f1_score,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/petadoption-mod/train_mod.csv\")\ntest=pd.read_csv(\"../input/petadoption-mod/test_mod.csv\")\n\n\n\n#label encoding the features for the modelling process\nle=LabelEncoder()\nle.fit(train[\"color_type\"])\n# train[\"color_type\"]=le.fit_transform(train[\"color_type\"])\ntrain[\"color_type\"]=le.transform(train[\"color_type\"])\ntest[\"color_type\"]=le.transform(test[\"color_type\"])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"Index(['pet_id', 'issue_date', 'listing_date', 'condition', 'color_type',\n       'length(m)', 'height(cm)', 'X1', 'X2', 'breed_category', 'pet_category',\n       'days_stayed', 'total_days_stayed', 'total_hours_stayed',\n       'condition_is_missing'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#some feature engineering\ntrain[\"length(m)\"]=train[\"length(m)\"]*100\ntest[\"length(m)\"]=test[\"length(m)\"]*100\n\ntrain[\"vol\"]=3.14*((train[\"height(cm)\"]/2)**2)*train[\"length(m)\"]\ntest[\"vol\"]=3.14*((test[\"height(cm)\"]/2)**2)*test[\"length(m)\"]\n\n# train[\"X1_X2\"]=train[\"X1\"]*train[\"X2\"]\n# test[\"X1_X2\"]=test[\"length(m)\"]*test[\"X2\"]\n\n\ntrain[\"Area_occupied\"]=train[\"length(m)\"]*train[\"height(cm)\"]\ntest[\"Area_occupied\"]=test[\"length(m)\"]*test[\"height(cm)\"]\n\ntrain_set,val_set=train_test_split(train,test_size=.25,random_state=42)\ntrain_set.shape,val_set.shape\n\n#-------------------------------------------------------------------------------\n#train_set\ntrain_data=train_set.drop(['pet_id', 'issue_date', 'listing_date','breed_category', 'pet_category','days_stayed']\n                          ,axis=1)\ntrain_res_breed=train_set.breed_category\ntrain_res_pet=train_set.pet_category\n\n#-------------------------------------------------------------------------------\n#val_set\nval_data=val_set.drop(['pet_id', 'issue_date', 'listing_date','breed_category', 'pet_category','days_stayed'],\n                     axis=1)\nval_res_breed=val_set.breed_category\nval_res_pet=val_set.pet_category\n#-------------------------------------------------------------------------------\ntrain_full=train.drop(['pet_id', 'issue_date', 'listing_date','breed_category', 'pet_category','days_stayed']\n                          ,axis=1)\ntrain_full_breed=train.breed_category\ntrain_full_pet=train.pet_category\ntest_full=test.drop(['pet_id', 'issue_date', 'listing_date','days_stayed']\n                          ,axis=1)\n\n#-------------------------------------------------------------------------------\n\ntrain_data.shape,train_res_breed.shape,val_data.shape,val_res_breed.shape,train_full.shape,test_full.shape","execution_count":7,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'len_in_cm'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'len_in_cm'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-208c6c53931d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Area_occupied\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"len_in_cm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height(cm)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Area_occupied\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"len_in_cm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height(cm)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'len_in_cm'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrc = LogisticRegression()\nrfc=RandomForestClassifier()\nadbc=AdaBoostClassifier()\nbgc=BaggingClassifier()\ngnb = GaussianNB()\nknn=KNeighborsClassifier()\ndtc = DecisionTreeClassifier()\nbgcl_lrc = BaggingClassifier(base_estimator=lrc, random_state=42)\nab_rfc = AdaBoostClassifier(base_estimator=rfc,random_state=42)\nab_dtc = AdaBoostClassifier(base_estimator=dtc,random_state=42)\nab_nbc=  AdaBoostClassifier(base_estimator=gnb,random_state=42)\nab_lrc=  AdaBoostClassifier(base_estimator=lrc,random_state=42)\ngbc=GradientBoostingClassifier()\nab_gbc=  AdaBoostClassifier(base_estimator=gbc,random_state=42)\nxgbc=XGBClassifier()\nab_xgbc=  AdaBoostClassifier(base_estimator=xgbc,random_state=42)\nlgbc=LGBMClassifier()\ncat=CatBoostClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=[rfc,adbc,bgc,gnb,knn,dtc,bgcl_lrc,ab_rfc,ab_dtc,ab_nbc,ab_lrc,gbc,ab_gbc,xgbc,ab_xgbc,lgbc]\nsctr,scte,auc,ps,rs=[],[],[],[],[]\ndef ensemble_for_train_val(X_train,y_train,X_test, y_test):\n    for model in models:\n        print(model.__class__.__name__)\n        model.fit(X_train, y_train)\n        y_test_pred = model.predict(X_test)\n        y_test_pred_new=model.predict_proba(X_test)\n        y_test_pred_new=y_test_pred_new[:,1]\n        train_score=model.score(X_train,y_train)\n        test_score=model.score(X_test,y_test)\n        p_score=metrics.precision_score(y_test,y_test_pred,average='micro')\n        r_score=metrics.recall_score(y_test,y_test_pred,average='micro')\n        \n        sctr.append(train_score)\n        scte.append(test_score)\n        ps.append(p_score)\n        rs.append(r_score)\n    return sctr,scte,ps,rs\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the performance on train and validation\nensemble_for_train_val(train_data,train_res_breed, val_data, val_res_breed)\n# 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n\nensemble=pd.DataFrame({'names':['Random Forest','Ada boost','Bagging',\n                                'Naive-Bayes','KNN','Decistion Tree',\n                                'bagged LR',\"adaboost rf\",\"adaboost dtc\",\"adaboost naive bayes\",\n                                \"adaboost logistic regression\",\"gradient boosting trees\"\n                                ,\"adaboost gbc\",\"xgboost\",\"adaboost xgbc\",\"lgbc\"],\n                       'training':sctr,'testing':scte,'precision':ps,'recall':rs,})\n\nensemble=ensemble.sort_values(by='precision',ascending=False).reset_index(drop=True)\nensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# models=[lgbc]\n# ensemble_for_train_val(train_data,train_res_breed, val_data, val_res_breed)\n\n# ensemble1=pd.DataFrame({'names':['lgbc'],\n#                        'training':sctr,'testing':scte,'precision':ps,'recall':rs,})\n# # ensemble=ensemble.sort_values(by='precision',ascending=False).reset_index(drop=True)\n# ensemble1\n\nmodels=[lgbc]\n\n# ensemble_for_train_val(train_full,train_full_breed, train_full_pet, test_full)\n\ndef pred_on_full_data(Xtrain,ytrain,ytrain2,Xtest,models):\n    for model in models:\n        print(model.__class__.__name__)\n        model.fit(Xtrain, ytrain)\n        y_test_pred_breed = model.predict(Xtest)\n        model.fit(Xtrain, ytrain2)\n        y_test_pred2_pet=model.predict(Xtest)\n        id=pd.Series(test[\"pet_id\"])\n        submission=pd.DataFrame({'pet_id':id,'breed_category':y_test_pred_breed,'pet_category':y_test_pred2_pet})\n#         predictions=pd.concat([test['INCIDENT_ID'],pd.DataFrame(y_test_pred,columns=['MULTIPLE_OFFENSE'])],1)\n        a=\"submission_multiple_\"+model.__class__.__name__+\"submission.csv\"\n        submission.to_csv(a,index=False)\n        \n\n#getting predictions on full data\npred_on_full_data(Xtrain=train_full,ytrain=train_full_breed,ytrain2=train_full_pet,Xtest=test_full,models=models)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_graph(a):\n    plt.figure(figsize=(8,6))\n    chart=sns.barplot(x=a[\"name_of_column\"],y=a[\"feature_importance\"])\n    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n    plt.show()\ndef feature_importance_plot_rev(dataframe,classifier,limit_of_the_importance):\n    x=list(zip(dataframe.columns,classifier.feature_importances_))\n    xx=pd.DataFrame(x)\n    xx.columns=[\"name_of_column\",\"feature_importance\"]\n    xx=xx.sort_values(\"feature_importance\",ascending=False)\n    xx=xx[xx[\"feature_importance\"]>limit_of_the_importance]\n    plot_graph(xx)\n    return xx\n\n# models=[lgbc]\n# for model in models:\n#     print(model)\n#     features=feature_importance_plot_rev(train_full,model,-1000)\n    \n#     print(model.__class__.__name__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbc.fit(train_full,train_full_breed)\nimportant_features_breed=feature_importance_plot_rev(train_full,lgbc,-1000)\nimportant_features_breed[\"name_of_column\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlgbc.fit(train_full,train_full_pet)\nimportant_features_pet=feature_importance_plot_rev(train_full,lgbc,-1000)\nimportant_features_pet[\"name_of_column\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_stacking():\n    # define the base models\n    level0 = list()\n    level0.append(('gbc', GradientBoostingClassifier()))\n#     level0.append((\"lgbc\",LGBMClassifier()))\n    # define meta learner model\n    level1 = LGBMClassifier()\n    # define the stacking ensemble\n    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n    return model\n# get a list of models to evaluate\ndef get_models():\n\tmodels = dict()\n\tmodels['stacking'] = get_stacking()\n\treturn models\n\n# evaluate a give model using cross-validation\ndef evaluate_model(model, X, y):\n\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\tscores = cross_val_score(model, X, y, scoring='precision', cv=cv, n_jobs=-1, error_score='raise')\n\treturn scores\n\nmodels_stacked = get_stacking()\n\nmodels=[models_stacked]\n\n# ensemble_for_train_val(train_full,train_full_breed, train_full_pet, test_full)\n\ndef pred_on_full_data(Xtrain,ytrain,ytrain2,Xtest,models):\n    for model in models:\n        print(model.__class__.__name__)\n        model.fit(Xtrain, ytrain)\n        y_test_pred_breed = model.predict(Xtest)\n        model.fit(Xtrain, ytrain2)\n        y_test_pred2_pet=model.predict(Xtest)\n        id=pd.Series(test[\"pet_id\"])\n        submission=pd.DataFrame({'pet_id':id,'breed_category':y_test_pred_breed,'pet_category':y_test_pred2_pet})\n#         predictions=pd.concat([test['INCIDENT_ID'],pd.DataFrame(y_test_pred,columns=['MULTIPLE_OFFENSE'])],1)\n        a=\"submission_multiple_stacked11\"+model.__class__.__name__+\"submission.csv\"\n        submission.to_csv(a,index=False)\n        \n\n#getting predictions on full data\npred_on_full_data(Xtrain=train_full,ytrain=train_full_breed,ytrain2=train_full_pet,Xtest=test_full,models=models)\n\n\n\n# # evaluate the models and store results\n# results, names = list(), list()\n# for name, model in models.items():\n# \tscores = evaluate_model(model, train_full, train_full_breed)\n# \tresults.append(scores)\n# \tnames.append(name)\n# \tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}