{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy.stats as st\n",
    "import sklearn.metrics as metrics\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import r2_score,roc_auc_score,recall_score,classification_report,mean_squared_error,accuracy_score,f1_score,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE,SVMSMOTE,KMeansSMOTE,SMOTENC,BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train_mod.csv\")\n",
    "test=pd.read_csv(\"test_mod.csv\")\n",
    "\n",
    "#label encoding the features for the modelling process\n",
    "le=LabelEncoder()\n",
    "le.fit(train[\"color_type\"])\n",
    "# train[\"color_type\"]=le.fit_transform(train[\"color_type\"])\n",
    "train[\"color_type\"]=le.transform(train[\"color_type\"])\n",
    "test[\"color_type\"]=le.transform(test[\"color_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full=train.drop(['pet_id', 'issue_date', 'listing_date','breed_category', 'pet_category','days_stayed']\n",
    "                          ,axis=1)\n",
    "train_full_breed=train.breed_category\n",
    "train_full_pet=train.pet_category\n",
    "test_full=test.drop(['pet_id', 'issue_date', 'listing_date','days_stayed']\n",
    "                          ,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KMeansSMOTE in module imblearn.over_sampling._smote:\n",
      "\n",
      "class KMeansSMOTE(BaseSMOTE)\n",
      " |  KMeansSMOTE(sampling_strategy='auto', random_state=None, k_neighbors=2, n_jobs=None, kmeans_estimator=None, cluster_balance_threshold='auto', density_exponent='auto')\n",
      " |  \n",
      " |  Apply a KMeans clustering before to over-sample using SMOTE.\n",
      " |  \n",
      " |  This is an implementation of the algorithm described in [1]_.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <smote_adasyn>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  sampling_strategy : float, str, dict or callable, default='auto'\n",
      " |      Sampling information to resample the data set.\n",
      " |  \n",
      " |      - When ``float``, it corresponds to the desired ratio of the number of\n",
      " |        samples in the minority class over the number of samples in the\n",
      " |        majority class after resampling. Therefore, the ratio is expressed as\n",
      " |        :math:`\\alpha_{os} = N_{rm} / N_{M}` where :math:`N_{rm}` is the\n",
      " |        number of samples in the minority class after resampling and\n",
      " |        :math:`N_{M}` is the number of samples in the majority class.\n",
      " |  \n",
      " |          .. warning::\n",
      " |             ``float`` is only available for **binary** classification. An\n",
      " |             error is raised for multi-class classification.\n",
      " |  \n",
      " |      - When ``str``, specify the class targeted by the resampling. The\n",
      " |        number of samples in the different classes will be equalized.\n",
      " |        Possible choices are:\n",
      " |  \n",
      " |          ``'minority'``: resample only the minority class;\n",
      " |  \n",
      " |          ``'not minority'``: resample all classes but the minority class;\n",
      " |  \n",
      " |          ``'not majority'``: resample all classes but the majority class;\n",
      " |  \n",
      " |          ``'all'``: resample all classes;\n",
      " |  \n",
      " |          ``'auto'``: equivalent to ``'not majority'``.\n",
      " |  \n",
      " |      - When ``dict``, the keys correspond to the targeted classes. The\n",
      " |        values correspond to the desired number of samples for each targeted\n",
      " |        class.\n",
      " |  \n",
      " |      - When callable, function taking ``y`` and returns a ``dict``. The keys\n",
      " |        correspond to the targeted classes. The values correspond to the\n",
      " |        desired number of samples for each class.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Control the randomization of the algorithm.\n",
      " |  \n",
      " |      - If int, ``random_state`` is the seed used by the random number\n",
      " |        generator;\n",
      " |      - If ``RandomState`` instance, random_state is the random number\n",
      " |        generator;\n",
      " |      - If ``None``, the random number generator is the ``RandomState``\n",
      " |        instance used by ``np.random``.\n",
      " |  \n",
      " |  k_neighbors : int or object, default=2\n",
      " |      If ``int``, number of nearest neighbours to used to construct synthetic\n",
      " |      samples.  If object, an estimator that inherits from\n",
      " |      :class:`sklearn.neighbors.base.KNeighborsMixin` that will be used to\n",
      " |      find the k_neighbors.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of CPU cores used during the cross-validation loop.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See\n",
      " |      `Glossary <https://scikit-learn.org/stable/glossary.html#term-n-jobs>`_\n",
      " |      for more details.\n",
      " |  \n",
      " |  kmeans_estimator : int or object, default=None\n",
      " |      A KMeans instance or the number of clusters to be used. By default,\n",
      " |      we used a :class:`sklearn.cluster.MiniBatchKMeans` which tend to be\n",
      " |      better with large number of samples.\n",
      " |  \n",
      " |  cluster_balance_threshold : \"auto\" or float, default=\"auto\"\n",
      " |      The threshold at which a cluster is called balanced and where samples\n",
      " |      of the class selected for SMOTE will be oversampled. If \"auto\", this\n",
      " |      will be determined by the ratio for each class, or it can be set\n",
      " |      manually.\n",
      " |  \n",
      " |  density_exponent : \"auto\" or float, default=\"auto\"\n",
      " |      This exponent is used to determine the density of a cluster. Leaving\n",
      " |      this to \"auto\" will use a feature-length based exponent.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  kmeans_estimator_ : estimator\n",
      " |      The fitted clustering method used before to apply SMOTE.\n",
      " |  \n",
      " |  nn_k_ : estimator\n",
      " |      The fitted k-NN estimator used in SMOTE.\n",
      " |  \n",
      " |  cluster_balance_threshold_ : float\n",
      " |      The threshold used during ``fit`` for calling a cluster balanced.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SMOTE : Over-sample using SMOTE.\n",
      " |  \n",
      " |  SVMSMOTE : Over-sample using SVM-SMOTE variant.\n",
      " |  \n",
      " |  BorderlineSMOTE : Over-sample using Borderline-SMOTE variant.\n",
      " |  \n",
      " |  ADASYN : Over-sample using ADASYN.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] Felix Last, Georgios Douzas, Fernando Bacao, \"Oversampling for\n",
      " |     Imbalanced Learning Based on K-Means and SMOTE\"\n",
      " |     https://arxiv.org/abs/1711.00837\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> from imblearn.over_sampling import KMeansSMOTE\n",
      " |  >>> from sklearn.datasets import make_blobs\n",
      " |  >>> blobs = [100, 800, 100]\n",
      " |  >>> X, y  = make_blobs(blobs, centers=[(-10, 0), (0,0), (10, 0)])\n",
      " |  >>> # Add a single 0 sample in the middle blob\n",
      " |  >>> X = np.concatenate([X, [[0, 0]]])\n",
      " |  >>> y = np.append(y, 0)\n",
      " |  >>> # Make this a binary classification problem\n",
      " |  >>> y = y == 1\n",
      " |  >>> sm = KMeansSMOTE(random_state=42)\n",
      " |  >>> X_res, y_res = sm.fit_resample(X, y)\n",
      " |  >>> # Find the number of new samples in the middle blob\n",
      " |  >>> n_res_in_middle = ((X_res[:, 0] > -5) & (X_res[:, 0] < 5)).sum()\n",
      " |  >>> print(\"Samples in the middle blob: %s\" % n_res_in_middle)\n",
      " |  Samples in the middle blob: 801\n",
      " |  >>> print(\"Middle blob unchanged: %s\" % (n_res_in_middle == blobs[1] + 1))\n",
      " |  Middle blob unchanged: True\n",
      " |  >>> print(\"More 0 samples: %s\" % ((y_res == 0).sum() > (y == 0).sum()))\n",
      " |  More 0 samples: True\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KMeansSMOTE\n",
      " |      BaseSMOTE\n",
      " |      imblearn.over_sampling.base.BaseOverSampler\n",
      " |      imblearn.base.BaseSampler\n",
      " |      imblearn.base.SamplerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sampling_strategy='auto', random_state=None, k_neighbors=2, n_jobs=None, kmeans_estimator=None, cluster_balance_threshold='auto', density_exponent='auto')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from imblearn.base.SamplerMixin:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Check inputs and statistics of the sampler.\n",
      " |      \n",
      " |      You should use ``fit_resample`` in all cases.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, dataframe, sparse matrix} of shape                 (n_samples, n_features)\n",
      " |          Data array.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Return the instance itself.\n",
      " |  \n",
      " |  fit_resample(self, X, y)\n",
      " |      Resample the dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, dataframe, sparse matrix} of shape                 (n_samples, n_features)\n",
      " |          Matrix containing the data which have to be sampled.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Corresponding label for each sample in X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_resampled : {array-like, dataframe, sparse matrix} of shape                 (n_samples_new, n_features)\n",
      " |          The array containing the resampled data.\n",
      " |      \n",
      " |      y_resampled : array-like of shape (n_samples_new,)\n",
      " |          The corresponding label of `X_resampled`.\n",
      " |  \n",
      " |  fit_sample = fit_resample(self, X, y)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KMeansSMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27000, 9), (27000,), (42484, 9), (42484,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = BorderlineSMOTE(random_state = 42)\n",
    "X_train_breed, y_train_breed = sm.fit_sample(train_full, train_full_breed.ravel())\n",
    "X_train_pet, y_train_pet = sm.fit_sample(train_full, train_full_pet.ravel())\n",
    "\n",
    "X_train_breed.shape,y_train_breed.shape,X_train_pet.shape,y_train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No samples will be generated with the provided ratio settings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-181af16d2314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_breed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_breed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_breed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_breed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train_pet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train_breed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_breed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train_pet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_pet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_adasyn.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[1;34m\"No samples will be generated with the\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                     \u001b[1;34m\" provided ratio settings.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: No samples will be generated with the provided ratio settings."
     ]
    }
   ],
   "source": [
    "# X_train_breed, y_train_breed = sm.fit_sample(X_train_breed, y_train_breed.ravel())\n",
    "# X_train_pet, y_train_pet = sm.fit_sample(X_train_pet, y_train_pet.ravel())\n",
    "# X_train_breed.shape,y_train_breed.shape,X_train_pet.shape,y_train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x3bb5819e08>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQZUlEQVR4nO3df6zddX3H8edLKv6YQ0Cq07asLDYquhmxAyaLGrtAQWeJAYOb0mCXLgsyXNwc7I91AVk0c2Ng1KSRanFGJOgGc26kQdTMKdKKUaBjbdDBlUrrikhm1FXf++N8qke4LZdP7z3nnt7nIzk53+/7+/me8/6etH31++N8T6oKSZJ6PGncDUiSJpchIknqZohIkroZIpKkboaIJKnbonE3MGrHHXdcLV++fNxtSNLE2LZt23eravF0yxZciCxfvpytW7eOuw1JmhhJ/vtAyzycJUnqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSeq24L6x/nhe/mfXjruFeWPb35x/yK9x32W/PgudHB6O/8tvHNL6p73vtFnqZPJ98aIvHvJrfP6Vr5qFTg4Pr/rC57vXdU9EktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVK3OQuRJJuS7E5y51Dt2CRbkuxoz8e0epJcnWRnkq8nOWlonbVt/I4ka4fqL0/yjbbO1UkyV9siSZreXO6JfARY/ajaJcAtVbUCuKXNA5wJrGiP9cAHYRA6wAbgFOBkYMP+4Glj1g+t9+j3kiTNsTkLkar6ArD3UeU1wOY2vRk4e6h+bQ18GTg6yXOBM4AtVbW3qh4CtgCr27KjqupLVVXAtUOvJUkakVGfE3lOVe0CaM/PbvUlwP1D46Za7WD1qWnq00qyPsnWJFv37NlzyBshSRqYLyfWpzufUR31aVXVxqpaWVUrFy9e3NmiJOnRRh0iD7ZDUbTn3a0+BSwbGrcUeOBx6kunqUuSRmjUIXITsP8Kq7XAjUP189tVWqcCD7fDXTcDpyc5pp1QPx24uS17JMmp7aqs84deS5I0InP2eyJJPg68GjguyRSDq6zeDVyfZB1wH3BuG/4Z4CxgJ/AD4AKAqtqb5HLg9jbusqraf7L+jxhcAfY04F/bQ5I0QnMWIlX1pgMsWjXN2AIuPMDrbAI2TVPfCrzkUHqUJB2a+XJiXZI0gQwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt7GESJI/SXJXkjuTfDzJU5OckOS2JDuSfCLJkW3sU9r8zrZ8+dDrXNrq9yQ5YxzbIkkL2chDJMkS4I+BlVX1EuAI4DzgPcCVVbUCeAhY11ZZBzxUVc8HrmzjSHJiW+/FwGrgA0mOGOW2SNJCN67DWYuApyVZBDwd2AW8BrihLd8MnN2m17R52vJVSdLq11XVj6rqm8BO4OQR9S9JYgwhUlXfBt4L3McgPB4GtgHfq6p9bdgUsKRNLwHub+vua+OfNVyfZp1fkGR9kq1Jtu7Zs2d2N0iSFrBxHM46hsFexAnA84BfAs6cZmjtX+UAyw5Uf2yxamNVrayqlYsXL37iTUuSpjWOw1m/A3yzqvZU1f8BnwJeARzdDm8BLAUeaNNTwDKAtvyZwN7h+jTrSJJGYBwhch9wapKnt3Mbq4C7gVuBc9qYtcCNbfqmNk9b/tmqqlY/r129dQKwAvjKiLZBksTgBPdIVdVtSW4AvgrsA+4ANgL/AlyX5F2tdk1b5Rrgo0l2MtgDOa+9zl1JrmcQQPuAC6vqJyPdGEla4EYeIgBVtQHY8KjyvUxzdVVV/RA49wCvcwVwxaw3KEmaEb+xLknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6zShEktwyk9pMJTk6yQ1J/jPJ9iS/leTYJFuS7GjPx7SxSXJ1kp1Jvp7kpKHXWdvG70iytrcfSVKfg4ZIkqcmORY4Lskx7R/6Y5MsB553CO97FfBvVfVC4KXAduAS4JaqWgHc0uYBzgRWtMd64IOtt2OBDcApwMnAhv3BI0kajcfbE/lDYBvwwva8/3Ej8P6eN0xyFPBK4BqAqvpxVX0PWANsbsM2A2e36TXAtTXwZeDoJM8FzgC2VNXeqnoI2AKs7ulJktRn0cEWVtVVwFVJLqqq983Se/4asAf4cJKXMgili4HnVNWu9r67kjy7jV8C3D+0/lSrHaj+GEnWM9iL4fjjj5+lzZAkHTRE9quq9yV5BbB8eJ2qurbzPU8CLqqq25Jcxc8PXU0n07V0kPpji1UbgY0AK1eunHaMJOmJm+mJ9Y8C7wV+G/jN9ljZ+Z5TwFRV3dbmb2AQKg+2w1S0591D45cNrb8UeOAgdUnSiMxoT4RBYJxYVYf8v/iq+k6S+5O8oKruAVYBd7fHWuDd7fnGtspNwNuSXMfgJPrD7XDXzcBfD51MPx249FD7kyTN3ExD5E7gV4Bds/S+FwEfS3IkcC9wAYO9ouuTrAPuA85tYz8DnAXsBH7QxlJVe5NcDtzexl1WVXtnqT9J0gzMNESOA+5O8hXgR/uLVfX6njetqq8x/eGwVdOMLeDCA7zOJmBTTw+SpEM30xD5q7lsQpI0mWZ6ddbn57oRSdLkmVGIJHmEn18+eyTwZOB/q+qouWpMkjT/zXRP5JeH55OczeBWI5KkBazrLr5V9U/Aa2a5F0nShJnp4aw3DM0+icGVVX7zW5IWuJlenfW7Q9P7gG8xuDGiJGkBm+k5kQvmuhFJ0uSZ6b2zlib5xyS7kzyY5JNJls51c5Kk+W2mJ9Y/zOAeVs9jcLv1f241SdICNtMQWVxVH66qfe3xEWDxHPYlSZoAMw2R7yZ5c5Ij2uPNwP/MZWOSpPlvpiHyVuCNwHcY3Mn3HNrddCVJC9dML/G9HFjbfsucJMcy+JGqt85VY5Kk+W+meyK/sT9AYPBbHsDL5qYlSdKkmGmIPGnoFwT374nMdC9GknSYmmkQ/C3wH0luYHC7kzcCV8xZV5KkiTDTb6xfm2Qrg5suBnhDVd09p51Jkua9GR+SaqFhcEiSfqbrVvCSJIEhIkk6BIaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqdvYQqT9zO4dST7d5k9IcluSHUk+keTIVn9Km9/Zli8feo1LW/2eJGeMZ0skaeEa557IxcD2ofn3AFdW1QrgIWBdq68DHqqq5wNXtnEkORE4D3gxsBr4QJIjRtS7JIkxhUiSpcBrgQ+1+TC4zfwNbchm4Ow2vabN05avauPXANdV1Y+q6pvATuDk0WyBJAnGtyfy98A7gZ+2+WcB36uqfW1+CljSppcA9wO05Q+38T+rT7POL0iyPsnWJFv37Nkzm9shSQvayEMkyeuA3VW1bbg8zdB6nGUHW+cXi1Ubq2plVa1cvHjxE+pXknRg4/id9NOA1yc5C3gqcBSDPZOjkyxqextLgQfa+ClgGTCVZBHwTGDvUH2/4XUkSSMw8j2Rqrq0qpZW1XIGJ8Y/W1W/D9wKnNOGrQVubNM3tXna8s9WVbX6ee3qrROAFcBXRrQZkiTGsydyIH8OXJfkXcAdwDWtfg3w0SQ7GeyBnAdQVXcluZ7BT/buAy6sqp+Mvm1JWrjGGiJV9Tngc236Xqa5uqqqfgice4D1rwCumLsOJUkH4zfWJUndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVK3kYdIkmVJbk2yPcldSS5u9WOTbEmyoz0f0+pJcnWSnUm+nuSkodda28bvSLJ21NsiSQvdOPZE9gHvqKoXAacCFyY5EbgEuKWqVgC3tHmAM4EV7bEe+CAMQgfYAJwCnAxs2B88kqTRGHmIVNWuqvpqm34E2A4sAdYAm9uwzcDZbXoNcG0NfBk4OslzgTOALVW1t6oeArYAq0e4KZK04I31nEiS5cDLgNuA51TVLhgEDfDsNmwJcP/QalOtdqD6dO+zPsnWJFv37Nkzm5sgSQva2EIkyTOATwJvr6rvH2zoNLU6SP2xxaqNVbWyqlYuXrz4iTcrSZrWWEIkyZMZBMjHqupTrfxgO0xFe97d6lPAsqHVlwIPHKQuSRqRcVydFeAaYHtV/d3QopuA/VdYrQVuHKqf367SOhV4uB3uuhk4Pckx7YT66a0mSRqRRWN4z9OAtwDfSPK1VvsL4N3A9UnWAfcB57ZlnwHOAnYCPwAuAKiqvUkuB25v4y6rqr2j2QRJEowhRKrq35n+fAbAqmnGF3DhAV5rE7Bp9rqTJD0RfmNdktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHWb+BBJsjrJPUl2Jrlk3P1I0kIy0SGS5Ajg/cCZwInAm5KcON6uJGnhmOgQAU4GdlbVvVX1Y+A6YM2Ye5KkBSNVNe4euiU5B1hdVX/Q5t8CnFJVb3vUuPXA+jb7AuCekTb6xB0HfHfcTRxG/Dxnl5/n7JqEz/NXq2rxdAsWjbqTWZZpao9JxaraCGyc+3ZmR5KtVbVy3H0cLvw8Z5ef5+ya9M9z0g9nTQHLhuaXAg+MqRdJWnAmPURuB1YkOSHJkcB5wE1j7kmSFoyJPpxVVfuSvA24GTgC2FRVd425rdkwMYfeJoSf5+zy85xdE/15TvSJdUnSeE364SxJ0hgZIpKkbobIPONtXGZPkk1Jdie5c9y9TLoky5LcmmR7kruSXDzung4HSY5IckeST4+7l16GyDzibVxm3UeA1eNu4jCxD3hHVb0IOBW40D+bs+JiYPu4mzgUhsj84m1cZlFVfQHYO+4+DgdVtauqvtqmH2HwD9+S8XY12ZIsBV4LfGjcvRwKQ2R+WQLcPzQ/hX9RNc8kWQ68DLhtvJ1MvL8H3gn8dNyNHApDZH6Z0W1cpHFJ8gzgk8Dbq+r74+5nUiV5HbC7qraNu5dDZYjML97GRfNWkiczCJCPVdWnxt3PhDsNeH2SbzE4bP2aJP8w3pb6+GXDeSTJIuC/gFXAtxnc1uX3DpNv4Y9FO/Ty6ap6yZhbmWhJAmwG9lbV28fdz+EkyauBP62q1427lx7uicwjVbUP2H8bl+3A9QZIvyQfB74EvCDJVJJ14+5pgp0GvIXB/5i/1h5njbspjZ97IpKkbu6JSJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqdv/AzFCPIyBQ3roAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_train_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression()\n",
    "rfc=RandomForestClassifier()\n",
    "adbc=AdaBoostClassifier()\n",
    "bgc=BaggingClassifier()\n",
    "gnb = GaussianNB()\n",
    "knn=KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "bgcl_lrc = BaggingClassifier(base_estimator=lrc, random_state=42)\n",
    "ab_rfc = AdaBoostClassifier(base_estimator=rfc,random_state=42)\n",
    "ab_dtc = AdaBoostClassifier(base_estimator=dtc,random_state=42)\n",
    "ab_nbc=  AdaBoostClassifier(base_estimator=gnb,random_state=42)\n",
    "ab_lrc=  AdaBoostClassifier(base_estimator=lrc,random_state=42)\n",
    "gbc=GradientBoostingClassifier()\n",
    "ab_gbc=  AdaBoostClassifier(base_estimator=gbc,random_state=42)\n",
    "xgbc=XGBClassifier()\n",
    "ab_xgbc=  AdaBoostClassifier(base_estimator=xgbc,random_state=42)\n",
    "lgbc=LGBMClassifier()\n",
    "cat=CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "BaggingClassifier\n",
      "GaussianNB\n",
      "KNeighborsClassifier\n",
      "DecisionTreeClassifier\n",
      "BaggingClassifier\n",
      "GradientBoostingClassifier\n",
      "XGBClassifier\n",
      "LGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "models=[lrc,rfc,adbc,bgc,gnb,knn,dtc,bgcl_lrc,gbc,xgbc,lgbc]\n",
    "\n",
    "\n",
    "def pred_on_full_data(Xtrain,Xtrain2,ytrain,ytrain2,Xtest,models):\n",
    "    for model in models:\n",
    "        print(model.__class__.__name__)\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        y_test_pred_breed = model.predict(Xtest)\n",
    "        model.fit(Xtrain2, ytrain2)\n",
    "        y_test_pred2_pet=model.predict(Xtest)\n",
    "        id=pd.Series(test[\"pet_id\"])\n",
    "        submission=pd.DataFrame({'pet_id':id,'breed_category':y_test_pred_breed,'pet_category':y_test_pred2_pet})\n",
    "#         predictions=pd.concat([test['INCIDENT_ID'],pd.DataFrame(y_test_pred,columns=['MULTIPLE_OFFENSE'])],1)\n",
    "        a=\"submission_multiple_smote\"+model.__class__.__name__+\"submission.csv\"\n",
    "        submission.to_csv(a,index=False)\n",
    "        \n",
    "# catboost\n",
    "# models=[cat]\n",
    "\n",
    "\n",
    "# def pred_on_full_data(Xtrain,Xtrain2,ytrain,ytrain2,Xtest,models):\n",
    "#     for model in models:\n",
    "#         print(model.__class__.__name__)\n",
    "#         model.fit(Xtrain, ytrain)\n",
    "#         y_test_pred_breed = model.predict(Xtest)[:,0]\n",
    "#         model.fit(Xtrain2, ytrain2)\n",
    "#         y_test_pred2_pet=model.predict(Xtest)[:,0]\n",
    "#         id=pd.Series(test[\"pet_id\"])\n",
    "#         submission=pd.DataFrame({'pet_id':id,'breed_category':y_test_pred_breed,'pet_category':y_test_pred2_pet})\n",
    "# #         predictions=pd.concat([test['INCIDENT_ID'],pd.DataFrame(y_test_pred,columns=['MULTIPLE_OFFENSE'])],1)\n",
    "#         a=\"submission_multiple_\"+model.__class__.__name__+\"submission.csv\"\n",
    "#         submission.to_csv(a,index=False)\n",
    "# getting predictions on full data\n",
    "pred_on_full_data(Xtrain=X_train_breed,Xtrain2=X_train_pet,ytrain=y_train_breed,ytrain2=y_train_pet,Xtest=test_full,models=models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
